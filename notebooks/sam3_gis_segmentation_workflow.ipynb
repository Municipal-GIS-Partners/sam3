{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM3 GIS Segmentation Workflow\n",
    "\n",
    "This notebook provides an interactive workflow for:\n",
    "1. **Loading raster imagery** (GeoTIFF, etc.)\n",
    "2. **Viewing in an interactive Leaflet map** with `ipyleaflet`\n",
    "3. **Selecting segmentation points/boxes** interactively\n",
    "4. **Running SAM3 segmentation** on selected regions\n",
    "5. **Post-processing masks to vector geometries**\n",
    "6. **Exporting to File Geodatabase (.gdb)**\n",
    "\n",
    "---\n",
    "**Prerequisites:**\n",
    "- SAM3 installed (`pip install -e .` from sam3 repo)\n",
    "- HuggingFace authentication for model checkpoints\n",
    "- GDAL/rasterio for raster handling\n",
    "- Fiona/geopandas for vector export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install \"segment-geospatial[samgeo3]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"transformers\" \"huggingface-hub<1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Raster handling\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.transform import rowcol, xy\n",
    "from rasterio.features import shapes\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "# Vector handling\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape, mapping, Polygon, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "import fiona\n",
    "\n",
    "# Interactive mapping\n",
    "import ipyleaflet\n",
    "from ipyleaflet import Map, TileLayer, ImageOverlay, Marker, DrawControl, LayerGroup, GeoJSON\n",
    "from ipywidgets import widgets, Output, VBox, HBox, Label, Button, Text, Dropdown, FloatSlider\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# SAM3 imports\n",
    "from sam3.model_builder import build_sam3_image_model\n",
    "from sam3.model.sam3_image_processor import Sam3Processor\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize SAM3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SAM3 tokenizer path (FIX for FileNotFoundError) ---\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "BPE_PATH = Path(\"/home/john/DevDrive/sam3/sam3/assets/bpe_simple_vocab_16e6.txt.gz\")\n",
    "\n",
    "# ✅ Only load once per kernel\n",
    "if \"model\" not in globals():\n",
    "\n",
    "    print(\"Loading SAM3 model (this may take a moment)...\")\n",
    "\n",
    "    model = build_sam3_image_model(\n",
    "        bpe_path=str(BPE_PATH),\n",
    "        load_from_HF=True,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "\n",
    "    model.eval()  # ✅ important for memory + inference stability\n",
    "    processor = Sam3Processor(model)\n",
    "\n",
    "    print(\"SAM3 model loaded successfully!\")\n",
    "\n",
    "else:\n",
    "    print(\"SAM3 model already loaded — reusing existing GPU instance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Raster Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoRasterLoader:\n",
    "    \"\"\"\n",
    "    Handles loading and georeferencing of raster imagery for SAM3 segmentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, raster_path: str):\n",
    "        self.raster_path = Path(raster_path)\n",
    "        self.src = None\n",
    "        self.transform = None\n",
    "        self.crs = None\n",
    "        self.bounds = None\n",
    "        self.image_array = None\n",
    "        self.image_pil = None\n",
    "        self._load_raster()\n",
    "    \n",
    "    def _load_raster(self):\n",
    "        \"\"\"Load raster and extract geospatial metadata.\"\"\"\n",
    "        self.src = rasterio.open(self.raster_path)\n",
    "        self.transform = self.src.transform\n",
    "        self.crs = self.src.crs\n",
    "        self.bounds = self.src.bounds\n",
    "        self.width = self.src.width\n",
    "        self.height = self.src.height\n",
    "        \n",
    "        # Read image data (handle different band configurations)\n",
    "        if self.src.count >= 3:\n",
    "            # RGB or multi-band - read first 3 bands\n",
    "            self.image_array = self.src.read([1, 2, 3]).transpose(1, 2, 0)\n",
    "        elif self.src.count == 1:\n",
    "            # Single band - convert to grayscale RGB\n",
    "            band = self.src.read(1)\n",
    "            self.image_array = np.stack([band, band, band], axis=-1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported band count: {self.src.count}\")\n",
    "        \n",
    "        # Normalize to 0-255 uint8 if needed\n",
    "        if self.image_array.dtype != np.uint8:\n",
    "            arr_min, arr_max = self.image_array.min(), self.image_array.max()\n",
    "            self.image_array = ((self.image_array - arr_min) / (arr_max - arr_min) * 255).astype(np.uint8)\n",
    "        \n",
    "        self.image_pil = Image.fromarray(self.image_array)\n",
    "        \n",
    "        print(f\"Loaded raster: {self.raster_path.name}\")\n",
    "        print(f\"  Size: {self.width} x {self.height}\")\n",
    "        print(f\"  CRS: {self.crs}\")\n",
    "        print(f\"  Bounds: {self.bounds}\")\n",
    "    \n",
    "    def pixel_to_geo(self, col: int, row: int) -> tuple:\n",
    "        \"\"\"Convert pixel coordinates to geographic coordinates.\"\"\"\n",
    "        return xy(self.transform, row, col)\n",
    "    \n",
    "    def geo_to_pixel(self, x: float, y: float) -> tuple:\n",
    "        \"\"\"Convert geographic coordinates to pixel coordinates.\"\"\"\n",
    "        row, col = rowcol(self.transform, x, y)\n",
    "        return col, row\n",
    "    \n",
    "    def get_bounds_wgs84(self) -> tuple:\n",
    "        \"\"\"Get bounds in WGS84 (lat/lon) for Leaflet.\"\"\"\n",
    "        from pyproj import Transformer\n",
    "        \n",
    "        if self.crs.to_epsg() == 4326:\n",
    "            return [\n",
    "                [self.bounds.bottom, self.bounds.left],\n",
    "                [self.bounds.top, self.bounds.right]\n",
    "            ]\n",
    "        \n",
    "        transformer = Transformer.from_crs(self.crs, \"EPSG:4326\", always_xy=True)\n",
    "        min_lon, min_lat = transformer.transform(self.bounds.left, self.bounds.bottom)\n",
    "        max_lon, max_lat = transformer.transform(self.bounds.right, self.bounds.top)\n",
    "        \n",
    "        return [[min_lat, min_lon], [max_lat, max_lon]]\n",
    "    \n",
    "    def get_center_wgs84(self) -> tuple:\n",
    "        \"\"\"Get center point in WGS84 (lat, lon) for Leaflet.\"\"\"\n",
    "        bounds = self.get_bounds_wgs84()\n",
    "        lat = (bounds[0][0] + bounds[1][0]) / 2\n",
    "        lon = (bounds[0][1] + bounds[1][1]) / 2\n",
    "        return (lat, lon)\n",
    "    \n",
    "    def save_png_for_overlay(self, output_path: str = None) -> str:\n",
    "        \"\"\"Save image as PNG for Leaflet overlay.\"\"\"\n",
    "        if output_path is None:\n",
    "            output_path = str(self.raster_path.with_suffix('.png'))\n",
    "        self.image_pil.save(output_path)\n",
    "        return output_path\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the raster file.\"\"\"\n",
    "        if self.src:\n",
    "            self.src.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Your Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURE YOUR RASTER PATH HERE ===\n",
    "RASTER_PATH = \"/home/john/DevDrive/sam3/sam3/assets/gis_segmentation_test_data/10259550.tif\"  # <-- Update this path\n",
    "\n",
    "# Load the raster\n",
    "raster = GeoRasterLoader(RASTER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Map with Selection Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAM3MapInterface:\n",
    "    \"\"\"\n",
    "    Interactive map interface for SAM3 segmentation with ipyleaflet.\n",
    "    Supports point clicks and box drawing for segmentation prompts.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, raster_loader: GeoRasterLoader, processor: Sam3Processor):\n",
    "        self.raster = raster_loader\n",
    "        self.processor = processor\n",
    "        self.inference_state = None\n",
    "        \n",
    "        # Storage for prompts and results\n",
    "        self.point_prompts = []  # List of (x, y, label) in pixel coords\n",
    "        self.box_prompts = []    # List of [x1, y1, x2, y2] in pixel coords\n",
    "        self.text_prompt = \"\"    # Text prompt for concept segmentation\n",
    "        self.current_masks = None\n",
    "        self.current_scores = None\n",
    "        self.mask_geometries = []  # GeoJSON geometries of masks\n",
    "        \n",
    "        # Initialize map and widgets\n",
    "        self._setup_map()\n",
    "        self._setup_controls()\n",
    "        self._setup_sam3_image()\n",
    "    \n",
    "    def _setup_sam3_image(self):\n",
    "        \"\"\"Pre-compute image embeddings for SAM3.\"\"\"\n",
    "        print(\"Computing image embeddings...\")\n",
    "        self.inference_state = self.processor.set_image(self.raster.image_pil)\n",
    "        print(\"Image embeddings ready!\")\n",
    "    \n",
    "    def _setup_map(self):\n",
    "        \"\"\"Initialize the Leaflet map with raster overlay.\"\"\"\n",
    "        center = self.raster.get_center_wgs84()\n",
    "        bounds = self.raster.get_bounds_wgs84()\n",
    "        \n",
    "        # Create map\n",
    "        self.map = Map(\n",
    "            center=center,\n",
    "            zoom=15,\n",
    "            scroll_wheel_zoom=True,\n",
    "            layout=widgets.Layout(width='100%', height='600px')\n",
    "        )\n",
    "        \n",
    "        # Add base layer options\n",
    "        self.basemap_osm = TileLayer(url='https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', name='OpenStreetMap')\n",
    "        self.basemap_satellite = TileLayer(\n",
    "            url='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
    "            name='Satellite'\n",
    "        )\n",
    "        self.map.add_layer(self.basemap_satellite)\n",
    "        \n",
    "        # Save raster as PNG and add as overlay\n",
    "        self.png_path = self.raster.save_png_for_overlay()\n",
    "        \n",
    "        # Create image overlay (for local files, we need to serve or embed)\n",
    "        # For local development, convert to base64\n",
    "        import base64\n",
    "        with open(self.png_path, 'rb') as f:\n",
    "            img_data = base64.b64encode(f.read()).decode()\n",
    "        img_url = f'data:image/png;base64,{img_data}'\n",
    "        \n",
    "        self.image_overlay = ImageOverlay(\n",
    "            url=img_url,\n",
    "            bounds=bounds,\n",
    "            name='Raster'\n",
    "        )\n",
    "        self.map.add_layer(self.image_overlay)\n",
    "        \n",
    "        # Layer for markers (point prompts)\n",
    "        self.marker_layer = LayerGroup(name='Points')\n",
    "        self.map.add_layer(self.marker_layer)\n",
    "        \n",
    "        # Layer for segmentation results\n",
    "        self.result_layer = LayerGroup(name='Segmentation')\n",
    "        self.map.add_layer(self.result_layer)\n",
    "        \n",
    "        # Draw control for boxes\n",
    "        self.draw_control = DrawControl(\n",
    "            rectangle={'shapeOptions': {'color': '#00ff00', 'fillOpacity': 0.2}},\n",
    "            polygon={},\n",
    "            polyline={},\n",
    "            circle={},\n",
    "            circlemarker={},\n",
    "            marker={}\n",
    "        )\n",
    "        self.draw_control.on_draw(self._handle_draw)\n",
    "        self.map.add_control(self.draw_control)\n",
    "        \n",
    "        # Handle map clicks for point prompts\n",
    "        self.map.on_interaction(self._handle_click)\n",
    "        \n",
    "        # Fit bounds\n",
    "        self.map.fit_bounds(bounds)\n",
    "    \n",
    "    def _setup_controls(self):\n",
    "        \"\"\"Setup control widgets.\"\"\"\n",
    "        # Output area for status/results\n",
    "        self.output = Output(layout=widgets.Layout(width='100%', height='200px', overflow='auto'))\n",
    "        \n",
    "        # Text prompt input\n",
    "        self.text_input = Text(\n",
    "            placeholder='Enter text prompt (e.g., \"building\", \"road\", \"vegetation\")',\n",
    "            description='Text Prompt:',\n",
    "            layout=widgets.Layout(width='400px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Point label selector (positive/negative)\n",
    "        self.point_label = Dropdown(\n",
    "            options=[('Positive (include)', 1), ('Negative (exclude)', 0)],\n",
    "            value=1,\n",
    "            description='Click Mode:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Confidence threshold\n",
    "        self.confidence_slider = FloatSlider(\n",
    "            value=0.5,\n",
    "            min=0.0,\n",
    "            max=1.0,\n",
    "            step=0.05,\n",
    "            description='Min Confidence:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Action buttons\n",
    "        self.segment_btn = Button(description='Run Segmentation', button_style='success')\n",
    "        self.segment_btn.on_click(self._run_segmentation)\n",
    "        \n",
    "        self.clear_btn = Button(description='Clear Prompts', button_style='warning')\n",
    "        self.clear_btn.on_click(self._clear_prompts)\n",
    "        \n",
    "        self.export_btn = Button(description='Export to GDB', button_style='info')\n",
    "        self.export_btn.on_click(self._export_to_gdb)\n",
    "        \n",
    "        # Layout\n",
    "        controls_row1 = HBox([self.text_input, self.point_label])\n",
    "        controls_row2 = HBox([self.confidence_slider, self.segment_btn, self.clear_btn, self.export_btn])\n",
    "        \n",
    "        self.controls = VBox([controls_row1, controls_row2])\n",
    "    \n",
    "    def _handle_click(self, **kwargs):\n",
    "        \"\"\"Handle map click events for point prompts.\"\"\"\n",
    "        if kwargs.get('type') == 'click':\n",
    "            coords = kwargs.get('coordinates')\n",
    "            if coords:\n",
    "                lat, lon = coords\n",
    "                \n",
    "                # Convert to pixel coordinates\n",
    "                from pyproj import Transformer\n",
    "                \n",
    "                if self.raster.crs.to_epsg() != 4326:\n",
    "                    transformer = Transformer.from_crs(\"EPSG:4326\", self.raster.crs, always_xy=True)\n",
    "                    x, y = transformer.transform(lon, lat)\n",
    "                else:\n",
    "                    x, y = lon, lat\n",
    "                \n",
    "                col, row = self.raster.geo_to_pixel(x, y)\n",
    "                \n",
    "                # Check if within bounds\n",
    "                if 0 <= col < self.raster.width and 0 <= row < self.raster.height:\n",
    "                    label = self.point_label.value\n",
    "                    self.point_prompts.append((col, row, label))\n",
    "                    \n",
    "                    # Add marker\n",
    "                    color = 'green' if label == 1 else 'red'\n",
    "                    marker = Marker(\n",
    "                        location=(lat, lon),\n",
    "                        draggable=False,\n",
    "                        title=f\"{'Positive' if label == 1 else 'Negative'} point\"\n",
    "                    )\n",
    "                    self.marker_layer.add_layer(marker)\n",
    "                    \n",
    "                    with self.output:\n",
    "                        print(f\"Added {'positive' if label == 1 else 'negative'} point at pixel ({col}, {row})\")\n",
    "    \n",
    "    def _handle_draw(self, target, action, geo_json):\n",
    "        \"\"\"Handle draw events for box prompts.\"\"\"\n",
    "        if action == 'created' and geo_json['geometry']['type'] == 'Polygon':\n",
    "            coords = geo_json['geometry']['coordinates'][0]\n",
    "            \n",
    "            # Get bounding box from polygon coords\n",
    "            lons = [c[0] for c in coords]\n",
    "            lats = [c[1] for c in coords]\n",
    "            \n",
    "            from pyproj import Transformer\n",
    "            \n",
    "            if self.raster.crs.to_epsg() != 4326:\n",
    "                transformer = Transformer.from_crs(\"EPSG:4326\", self.raster.crs, always_xy=True)\n",
    "                x_coords = []\n",
    "                y_coords = []\n",
    "                for lon, lat in zip(lons, lats):\n",
    "                    x, y = transformer.transform(lon, lat)\n",
    "                    x_coords.append(x)\n",
    "                    y_coords.append(y)\n",
    "            else:\n",
    "                x_coords, y_coords = lons, lats\n",
    "            \n",
    "            # Convert to pixel coordinates\n",
    "            min_x, max_x = min(x_coords), max(x_coords)\n",
    "            min_y, max_y = min(y_coords), max(y_coords)\n",
    "            \n",
    "            col1, row1 = self.raster.geo_to_pixel(min_x, max_y)  # top-left\n",
    "            col2, row2 = self.raster.geo_to_pixel(max_x, min_y)  # bottom-right\n",
    "            \n",
    "            # Clamp to image bounds\n",
    "            col1 = max(0, min(col1, self.raster.width - 1))\n",
    "            col2 = max(0, min(col2, self.raster.width - 1))\n",
    "            row1 = max(0, min(row1, self.raster.height - 1))\n",
    "            row2 = max(0, min(row2, self.raster.height - 1))\n",
    "            \n",
    "            self.box_prompts.append([col1, row1, col2, row2])\n",
    "            \n",
    "            with self.output:\n",
    "                print(f\"Added box prompt: ({col1}, {row1}) to ({col2}, {row2})\")\n",
    "    \n",
    "    def _run_segmentation(self, btn=None):\n",
    "        \"\"\"Execute SAM3 segmentation with current prompts.\"\"\"\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Running SAM3 segmentation...\")\n",
    "            \n",
    "            try:\n",
    "                # Reset inference state for fresh prompts\n",
    "                self.inference_state = self.processor.set_image(self.raster.image_pil)\n",
    "                \n",
    "                # Determine prompt type\n",
    "                text = self.text_input.value.strip()\n",
    "                \n",
    "                if text:\n",
    "                    # Text prompt segmentation (Promptable Concept Segmentation)\n",
    "                    print(f\"Using text prompt: '{text}'\")\n",
    "                    \n",
    "                    output = self.processor.set_text_prompt(\n",
    "                        state=self.inference_state,\n",
    "                        prompt=text\n",
    "                    )\n",
    "                    \n",
    "                    self.current_masks = output[\"masks\"]\n",
    "                    self.current_scores = output[\"scores\"]\n",
    "                    boxes = output.get(\"boxes\", [])\n",
    "\n",
    "                    # ======================================================\n",
    "                    # ✅ DEBUG BLOCK – RAW SCORE INSPECTION (TEXT MODE)\n",
    "                    # ======================================================\n",
    "                    min_conf = self.confidence_slider.value\n",
    "\n",
    "                    print(\"\\n=== SAM3 SCORE DEBUG ===\")\n",
    "                    print(\"Prompt:\", text)\n",
    "                    print(\"Min confidence slider:\", min_conf)\n",
    "\n",
    "                    if self.current_scores:\n",
    "                        scores = [\n",
    "                            s.item() if isinstance(s, torch.Tensor) else float(s)\n",
    "                            for s in self.current_scores\n",
    "                        ]\n",
    "                        print(\"Total regions:\", len(scores))\n",
    "                        print(\"Max score:\", max(scores))\n",
    "                        print(\"Mean score:\", sum(scores) / len(scores))\n",
    "                        print(\"Top 10 scores:\", sorted(scores, reverse=True)[:10])\n",
    "                    else:\n",
    "                        print(\"No scores returned at all\")\n",
    "\n",
    "                    print(\"========================\\n\")\n",
    "                    # ======================================================\n",
    "                    \n",
    "                elif self.point_prompts or self.box_prompts:\n",
    "                    # Visual prompt segmentation (Promptable Visual Segmentation)\n",
    "                    print(f\"Using {len(self.point_prompts)} point(s) and {len(self.box_prompts)} box(es)\")\n",
    "                    \n",
    "                    # Format prompts for SAM3\n",
    "                    if self.point_prompts:\n",
    "                        points = [[p[0], p[1]] for p in self.point_prompts]\n",
    "                        labels = [p[2] for p in self.point_prompts]\n",
    "                        output = self.processor.set_point_prompt(\n",
    "                            state=self.inference_state,\n",
    "                            points=points,\n",
    "                            labels=labels\n",
    "                        )\n",
    "                    elif self.box_prompts:\n",
    "                        output = self.processor.set_box_prompt(\n",
    "                            state=self.inference_state,\n",
    "                            box=self.box_prompts[0]  # Use first box\n",
    "                        )\n",
    "                    \n",
    "                    self.current_masks = output[\"masks\"]\n",
    "                    self.current_scores = output.get(\"scores\", [1.0] * len(output[\"masks\"]))\n",
    "                    \n",
    "                else:\n",
    "                    print(\"No prompts specified! Click on map to add points, draw boxes, or enter text.\")\n",
    "                    return\n",
    "                \n",
    "                # Filter by confidence\n",
    "                min_conf = self.confidence_slider.value\n",
    "                \n",
    "                # Convert masks to geometries and display\n",
    "                self._process_masks(min_conf)\n",
    "                \n",
    "                print(f\"Segmentation complete! Found {len(self.mask_geometries)} region(s)\")\n",
    "\n",
    "    def _process_masks(self, min_confidence: float):\n",
    "        \"\"\"Convert mask arrays to georeferenced geometries.\"\"\"\n",
    "        self.mask_geometries = []\n",
    "        \n",
    "        # Clear previous results\n",
    "        self.result_layer.clear_layers()\n",
    "        \n",
    "        if self.current_masks is None:\n",
    "            return\n",
    "        \n",
    "        for i, (mask, score) in enumerate(zip(self.current_masks, self.current_scores)):\n",
    "            # Handle different mask formats\n",
    "            if isinstance(score, torch.Tensor):\n",
    "                score = score.item()\n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "            \n",
    "            if score < min_confidence:\n",
    "                continue\n",
    "            \n",
    "            # Ensure mask is 2D binary\n",
    "            if mask.ndim > 2:\n",
    "                mask = mask.squeeze()\n",
    "            mask_binary = (mask > 0.5).astype(np.uint8)\n",
    "            \n",
    "            # Convert to vector using rasterio.features.shapes\n",
    "            for geom, value in shapes(mask_binary, transform=self.raster.transform):\n",
    "                if value == 1:\n",
    "                    # Convert to shapely geometry\n",
    "                    poly = shape(geom)\n",
    "                    \n",
    "                    # Store with metadata\n",
    "                    self.mask_geometries.append({\n",
    "                        'geometry': poly,\n",
    "                        'score': score,\n",
    "                        'mask_id': i,\n",
    "                        'prompt': self.text_input.value or 'visual_prompt'\n",
    "                    })\n",
    "                    \n",
    "                    # Convert to WGS84 for display\n",
    "                    self._add_geometry_to_map(poly, score)\n",
    "        \n",
    "        with self.output:\n",
    "            print(f\"Processed {len(self.mask_geometries)} geometries\")\n",
    "    \n",
    "    def _add_geometry_to_map(self, geometry, score: float):\n",
    "        \"\"\"Add a geometry to the map in WGS84.\"\"\"\n",
    "        from pyproj import Transformer\n",
    "        from shapely.ops import transform as shapely_transform\n",
    "        \n",
    "        # Transform to WGS84 if needed\n",
    "        if self.raster.crs.to_epsg() != 4326:\n",
    "            transformer = Transformer.from_crs(self.raster.crs, \"EPSG:4326\", always_xy=True)\n",
    "            geometry_wgs84 = shapely_transform(transformer.transform, geometry)\n",
    "        else:\n",
    "            geometry_wgs84 = geometry\n",
    "        \n",
    "        # Create GeoJSON layer\n",
    "        geojson_data = {\n",
    "            'type': 'Feature',\n",
    "            'properties': {'score': score},\n",
    "            'geometry': mapping(geometry_wgs84)\n",
    "        }\n",
    "        \n",
    "        # Color based on score\n",
    "        color = f'#{int(255*(1-score)):02x}{int(255*score):02x}00'\n",
    "        \n",
    "        geojson_layer = GeoJSON(\n",
    "            data=geojson_data,\n",
    "            style={'color': color, 'fillColor': color, 'fillOpacity': 0.4, 'weight': 2}\n",
    "        )\n",
    "        self.result_layer.add_layer(geojson_layer)\n",
    "    \n",
    "    def _clear_prompts(self, btn=None):\n",
    "        \"\"\"Clear all prompts and results.\"\"\"\n",
    "        self.point_prompts = []\n",
    "        self.box_prompts = []\n",
    "        self.current_masks = None\n",
    "        self.current_scores = None\n",
    "        self.mask_geometries = []\n",
    "        \n",
    "        self.marker_layer.clear_layers()\n",
    "        self.result_layer.clear_layers()\n",
    "        self.draw_control.clear()\n",
    "        \n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Cleared all prompts and results\")\n",
    "    \n",
    "    def _export_to_gdb(self, btn=None):\n",
    "        \"\"\"Export segmentation results to File Geodatabase.\"\"\"\n",
    "        with self.output:\n",
    "            if not self.mask_geometries:\n",
    "                print(\"No geometries to export! Run segmentation first.\")\n",
    "                return\n",
    "            \n",
    "            # Create output path\n",
    "            output_gdb = self.raster.raster_path.parent / f\"{self.raster.raster_path.stem}_segments.gdb\"\n",
    "            \n",
    "            print(f\"Exporting to: {output_gdb}\")\n",
    "            \n",
    "            # Create GeoDataFrame\n",
    "            gdf = gpd.GeoDataFrame(\n",
    "                [\n",
    "                    {\n",
    "                        'geometry': g['geometry'],\n",
    "                        'score': g['score'],\n",
    "                        'mask_id': g['mask_id'],\n",
    "                        'prompt': g['prompt']\n",
    "                    }\n",
    "                    for g in self.mask_geometries\n",
    "                ],\n",
    "                crs=self.raster.crs\n",
    "            )\n",
    "            \n",
    "            # Export to GDB using Fiona's OpenFileGDB driver\n",
    "            try:\n",
    "                gdf.to_file(str(output_gdb), driver='OpenFileGDB', layer='segments')\n",
    "                print(f\"Successfully exported {len(gdf)} features to {output_gdb}\")\n",
    "            except Exception as e:\n",
    "                # Fallback to GeoPackage if OpenFileGDB not available\n",
    "                output_gpkg = output_gdb.with_suffix('.gpkg')\n",
    "                print(f\"OpenFileGDB driver not available. Exporting to GeoPackage: {output_gpkg}\")\n",
    "                gdf.to_file(str(output_gpkg), driver='GPKG', layer='segments')\n",
    "                print(f\"Successfully exported {len(gdf)} features to {output_gpkg}\")\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the complete interface.\"\"\"\n",
    "        return VBox([self.controls, self.map, self.output])\n",
    "    \n",
    "    def get_geodataframe(self) -> gpd.GeoDataFrame:\n",
    "        \"\"\"Get current segmentation results as GeoDataFrame.\"\"\"\n",
    "        if not self.mask_geometries:\n",
    "            return gpd.GeoDataFrame()\n",
    "        \n",
    "        return gpd.GeoDataFrame(\n",
    "            [\n",
    "                {\n",
    "                    'geometry': g['geometry'],\n",
    "                    'score': g['score'],\n",
    "                    'mask_id': g['mask_id'],\n",
    "                    'prompt': g['prompt']\n",
    "                }\n",
    "                for g in self.mask_geometries\n",
    "            ],\n",
    "            crs=self.raster.crs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Launch Interactive Map Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display the interactive interface\n",
    "map_interface = SAM3MapInterface(raster, processor)\n",
    "display(map_interface.display())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Use:\n",
    "\n",
    "1. **Text Prompt**: Enter a concept (e.g., \"building\", \"road\", \"tree\") and click \"Run Segmentation\"\n",
    "2. **Point Prompts**: \n",
    "   - Select \"Positive\" or \"Negative\" mode\n",
    "   - Click on the map to add points\n",
    "   - Green = include, Red = exclude\n",
    "3. **Box Prompts**: Draw rectangles on the map using the draw tool\n",
    "4. **Run Segmentation**: Click button to process\n",
    "5. **Export**: Click \"Export to GDB\" to save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 \"Normalize\" the segementations into GIS shapes and square geometry before export (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely import minimum_rotated_rectangle\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Get raw results\n",
    "gdf_raw = map_interface.get_geodataframe()\n",
    "\n",
    "# Square them (pick one method)\n",
    "gdf_raw['geometry'] = gdf_raw['geometry'].apply(minimum_rotated_rectangle)  # oriented box\n",
    "# OR\n",
    "# gdf_raw['geometry'] = gdf_raw['geometry'].apply(lambda g: box(*g.bounds))  # axis-aligned box\n",
    "\n",
    "# Export\n",
    "gdf_raw.to_file(\"output.gdb\", driver='OpenFileGDB', layer='segments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Manual Export Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results as GeoDataFrame for further processing\n",
    "gdf = map_interface.get_geodataframe()\n",
    "\n",
    "if not gdf.empty:\n",
    "    print(f\"GeoDataFrame with {len(gdf)} features\")\n",
    "    print(f\"CRS: {gdf.crs}\")\n",
    "    display(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to various formats\n",
    "def export_results(gdf: gpd.GeoDataFrame, output_dir: str, base_name: str = \"segments\"):\n",
    "    \"\"\"\n",
    "    Export GeoDataFrame to multiple formats.\n",
    "    \n",
    "    Args:\n",
    "        gdf: GeoDataFrame with segmentation results\n",
    "        output_dir: Output directory path\n",
    "        base_name: Base name for output files\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    if gdf.empty:\n",
    "        print(\"No features to export\")\n",
    "        return\n",
    "    \n",
    "    # File Geodatabase\n",
    "    try:\n",
    "        gdb_path = output_dir / f\"{base_name}.gdb\"\n",
    "        gdf.to_file(str(gdb_path), driver='OpenFileGDB', layer=base_name)\n",
    "        print(f\"✓ File Geodatabase: {gdb_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ File Geodatabase failed: {e}\")\n",
    "    \n",
    "    # GeoPackage\n",
    "    gpkg_path = output_dir / f\"{base_name}.gpkg\"\n",
    "    gdf.to_file(str(gpkg_path), driver='GPKG', layer=base_name)\n",
    "    print(f\"✓ GeoPackage: {gpkg_path}\")\n",
    "    \n",
    "    # Shapefile\n",
    "    shp_path = output_dir / f\"{base_name}.shp\"\n",
    "    gdf.to_file(str(shp_path), driver='ESRI Shapefile')\n",
    "    print(f\"✓ Shapefile: {shp_path}\")\n",
    "    \n",
    "    # GeoJSON\n",
    "    geojson_path = output_dir / f\"{base_name}.geojson\"\n",
    "    gdf.to_file(str(geojson_path), driver='GeoJSON')\n",
    "    print(f\"✓ GeoJSON: {geojson_path}\")\n",
    "    \n",
    "    return {\n",
    "        'gdb': gdb_path if gdb_path.exists() else None,\n",
    "        'gpkg': gpkg_path,\n",
    "        'shp': shp_path,\n",
    "        'geojson': geojson_path\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# export_results(gdf, \"./outputs\", \"my_segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Processing (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_segment_with_text(raster_path: str, text_prompts: list, output_gdb: str, \n",
    "                            min_confidence: float = 0.5):\n",
    "    \"\"\"\n",
    "    Batch process a raster with multiple text prompts.\n",
    "    \n",
    "    Args:\n",
    "        raster_path: Path to input raster\n",
    "        text_prompts: List of text prompts (e.g., [\"building\", \"road\", \"tree\"])\n",
    "        output_gdb: Output geodatabase path\n",
    "        min_confidence: Minimum confidence threshold\n",
    "    \"\"\"\n",
    "    # Load raster\n",
    "    raster = GeoRasterLoader(raster_path)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = build_sam3_image_model()\n",
    "    processor = Sam3Processor(model)\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    for prompt in text_prompts:\n",
    "        print(f\"Processing: '{prompt}'\")\n",
    "        \n",
    "        # Run segmentation\n",
    "        inference_state = processor.set_image(raster.image_pil)\n",
    "        output = processor.set_text_prompt(state=inference_state, prompt=prompt)\n",
    "        \n",
    "        masks = output[\"masks\"]\n",
    "        scores = output[\"scores\"]\n",
    "        \n",
    "        # Convert to geometries\n",
    "        for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "            if isinstance(score, torch.Tensor):\n",
    "                score = score.item()\n",
    "            if score < min_confidence:\n",
    "                continue\n",
    "            \n",
    "            if isinstance(mask, torch.Tensor):\n",
    "                mask = mask.cpu().numpy()\n",
    "            if mask.ndim > 2:\n",
    "                mask = mask.squeeze()\n",
    "            \n",
    "            mask_binary = (mask > 0.5).astype(np.uint8)\n",
    "            \n",
    "            for geom, value in shapes(mask_binary, transform=raster.transform):\n",
    "                if value == 1:\n",
    "                    all_results.append({\n",
    "                        'geometry': shape(geom),\n",
    "                        'class': prompt,\n",
    "                        'score': score,\n",
    "                        'mask_id': i\n",
    "                    })\n",
    "    \n",
    "    # Create GeoDataFrame and export\n",
    "    gdf = gpd.GeoDataFrame(all_results, crs=raster.crs)\n",
    "    \n",
    "    if not gdf.empty:\n",
    "        try:\n",
    "            gdf.to_file(output_gdb, driver='OpenFileGDB', layer='segments')\n",
    "        except:\n",
    "            gdf.to_file(output_gdb.replace('.gdb', '.gpkg'), driver='GPKG', layer='segments')\n",
    "        \n",
    "        print(f\"Exported {len(gdf)} features\")\n",
    "    \n",
    "    raster.close()\n",
    "    return gdf\n",
    "\n",
    "# Example batch processing:\n",
    "# gdf = batch_segment_with_text(\n",
    "#     \"path/to/raster.tif\",\n",
    "#     [\"building\", \"road\", \"vegetation\", \"water\"],\n",
    "#     \"./outputs/segments.gdb\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segmentation(raster: GeoRasterLoader, gdf: gpd.GeoDataFrame, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Visualize segmentation results overlaid on the raster.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(raster.image_array)\n",
    "    axes[0].set_title(\"Original Raster\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Image with segmentation overlay\n",
    "    axes[1].imshow(raster.image_array)\n",
    "    \n",
    "    if not gdf.empty:\n",
    "        # Create colormap for different classes/prompts\n",
    "        unique_prompts = gdf['prompt'].unique() if 'prompt' in gdf.columns else ['segment']\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_prompts)))\n",
    "        color_map = dict(zip(unique_prompts, colors))\n",
    "        \n",
    "        for idx, row in gdf.iterrows():\n",
    "            prompt = row.get('prompt', 'segment')\n",
    "            color = color_map[prompt]\n",
    "            \n",
    "            if row.geometry.geom_type == 'Polygon':\n",
    "                coords = np.array(row.geometry.exterior.coords)\n",
    "                # Convert geo coords to pixel coords\n",
    "                pixel_coords = np.array([raster.geo_to_pixel(x, y) for x, y in coords])\n",
    "                axes[1].fill(pixel_coords[:, 0], pixel_coords[:, 1], \n",
    "                           alpha=0.4, color=color, edgecolor=color, linewidth=2)\n",
    "            elif row.geometry.geom_type == 'MultiPolygon':\n",
    "                for poly in row.geometry.geoms:\n",
    "                    coords = np.array(poly.exterior.coords)\n",
    "                    pixel_coords = np.array([raster.geo_to_pixel(x, y) for x, y in coords])\n",
    "                    axes[1].fill(pixel_coords[:, 0], pixel_coords[:, 1], \n",
    "                               alpha=0.4, color=color, edgecolor=color, linewidth=2)\n",
    "        \n",
    "        # Add legend\n",
    "        legend_patches = [plt.Rectangle((0,0),1,1, fc=color_map[p], alpha=0.6) for p in unique_prompts]\n",
    "        axes[1].legend(legend_patches, unique_prompts, loc='upper right')\n",
    "    \n",
    "    axes[1].set_title(\"Segmentation Results\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results\n",
    "# visualize_segmentation(raster, gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close raster file when done\n",
    "raster.close()\n",
    "print(\"Cleanup complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
